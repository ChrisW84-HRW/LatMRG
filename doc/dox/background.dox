/**
 * \page background Theory of Random Numbers
 *
 * This page covers the theory specific to LatMRG in two main sections and a
 * third secondary one.
 * First, we present all the generators engines covered by the library. Along
 * with the generators definitions, we present the equivalences that make it
 * possible to study all those generatorse in LatMRG. In the second section,
 * we present the construction of lattices for such random generators, as well
 * as the computations to study such lattices. In the last section, we present
 * some issues arrising when choosing parameters for a generator. This is an
 * optionnal section that can be helpfull when starting searches with LatMRG.
 *
 * \section back_gen Linear Congruential Engines
 *
 * \subsection back_gen_gen Simple Congruential Generators
 *
 * We assume some familiarity with the concept of random number generator from
 * from the reader. If this is not the case, we recommend reading the beginning
 * of \cite rLEC17h.
 * Although this is not the shortest introduction to random number generators,
 * it is very well suited for beginners and it covers both historical and
 * modern issues of random number generation.
 *
 * We first present the oldest and simplest generator engine that LatMRG covers.
 * Given \f$a,m,c \in \mathbb{Z}\f$, usually also with the constraints
 * \f$0 < a < m\f$ and \f$0 \leq c < m,\ 1 \equiv c \pmod 2\f$, we can get
 * pseudo-random number in \f$(0,1)\f$ by generating the sequence \f$\{x_n\}\f$
 * \f[
 *   x_n = a x_{n-1} + c \pmod m
 * \f]
 * and by taking the output of \f$u_n = x_n / m\f$. Note that if \f$c = 0\f$,
 * the components also need to be such that \f$\gcd(a,m) = 1\f$.
 *
 * This kind of generator is called a **linear congruential generator** LCG. It is
 * easy to implement and runs fast. But as computing power grew,
 * It became clear that it was not practical to have a LCG as a random number
 * generator. These generator have a high correlation between their points.
 * It is also impractical to make on with a long enough period as the maximal
 * possible period for a LCG is \f$m-1\f$.
 *
 * The natural extension
 * of this engine that arose was the augmentation of the order of the
 * recurrence as follows:
 * \f[
 *   x_n = a_1 x_{n-1} + \cdots + a_k x_{n-k} \pmod m
 * \f]
 * where \f$a_k \neq 0\f$. This engine can output random numbers in the same
 * way by taking \f$u_n = x_n / m\f$. Using this kind of recurrence mostly solves
 * the problems of LCGs as it increases the states space considerably. This kind
 * of engine is called a **multiple recursive generator** (MRG). Note that LCG
 * generators simply are a specific case of MRG generators. It turns out that
 * most of the generators presented after this point are equivalent to a MRG
 * in some way and can be considered simply as MRGs when developping the theory.
 * This is for this reason that this software is called LatMRG. \ref back_other
 * presents the main results to study a MRG, but they also have been broadly
 * studied in the litterature in, for example, \cite rLEC93a \cite rLEC88a, and
 * \cite rLEC97b.
 *
 * \subsection back_gen_carry Carry Generators
 *
 * Using a MRG is much slower that using a LCG so many avenues have been
 * studied as a way to generate random numbers on a period large enough to be
 * useable, but that is faster than an MRG. This is what \cite rMAR91a
 * introduced. These engines are fast and also have long periods and use the
 * following recurrences with \f$r > s\f$ and \f$b \in \mathbb{Z}_{>0}\f$:
 * \f[
 *   \begin{array}{llll}
 *     \text{(AWC)} & x_n & = & x_{n-s} + x_{n-r} + c_n \pmod b, \\
 *     & c_{n+1} & = & \mathbb{1}(x_{n-s} + x_{i-r} + c_n \geq b). \\
 *     \text{(AWC-c)} & x_n & = & -x_{n-s} - x_{n-r} - c_n - 1 \pmod b,\\
 *     & c_{n+1} & = & \mathbb{1}(x_{n-s} + x_{i-r} + c_n \geq b).\\
 *     \text{(SWB-I)} & x_n & = & x_{n-s} - x_{n-r} - c_n \pmod b,\\
 *     & c_{n+1} & = & \mathbb{1}(x_{n-s} - x_{n-r} - c_n < 0).\\
 *     \text{(SWB-II)} & x_n & = & - x_{n-s} + x_{n-r} - c_n \pmod b,\\
 *     & c_{n+1} & = & \mathbb{1}(x_{n-s} - x_{n-r} - c_n < 0).\\
 *   \end{array}
 * \f]
 * These generators are called Add-with-Carry (AWC) and Subtract-with-Borrow
 * (SWB) (we follow the naming scheme of \cite rTEZ93a for the variants). The
 * fact that these generators do not need multiplication operations mean that
 * they will be very fast with b as a power of 2. With a good choice of
 * parameters, the period of the recurrence can be up to around \f$b^r\f$, which
 * means that this generator solves both the period length problem and the speed
 * one.
 *
 * The sequence \f$\{x_n\}\f$ can be used to generate random
 * \f$\mathcal{U}(0,1)\f$ numbers with an
 * arbitrary number of digits in base \f$b\f$ with
 * \f[
 *   u_n = \sum_{j=1}^L x_{Ln + j + 1} b^{-j}.
 * \f]
 * By taking \f$M\f$ as follows,
 * <center>
 * | Generator |  M        |
 * | :-------- | :-------------: |
 * | AWC       | \f$b^r+b^s-1\f$ |
 * | AWC-c     | \f$b^r+b^s+1\f$ |
 * | SWB-I     | \f$b^r-b^s+1\f$ |
 * | SWB-II    | \f$b^r-b^s-1\f$ |
 * </center>
 * We can build an equivalence between AWC/SWB generators and the following LCG
 * (\cite rTEZ93a)
 * \f{align}{
 *   X_n & = AX_{n-1} \pmod M \\
 *   v_n & = X_n / M \\
 *   w_n & = X_{Ln}/M.
 * \f}
 * When we say equivalence, this is in the sense that, with the right initial
 * state, the output \f$w_i\f$ and
 * \f$u_i\f$ have the same decimal digits in base \f$b\f$ up to the precision of
 * \f$u_i\f$. That is: \f$u_i = b^{-L} \lfloor b^L w_i \rfloor\f$.
 *
 * It turns out that AWC/SWB generators have a few faults in theoretical tests.
 * \cite rMAR94a suggested a similar kind of recurrence to solve this issue
 * called **multiply-with-carry** (MWC)
 * \f[
 *   \begin{array}{lll}
 *     x_n & = & (a_1 x_{n-1} + \cdots + a_k x_{n-k} + c_{n-1})d \pmod b,\\
 *     c_n & = & \lfloor (a_0 x_n + a_1 x_{n-1} + \cdots + a_k x_{n-k})/b\rfloor,
 *   \end{array}
 * \f]
 * where \f$\gcd(a_0, b) = 1\f$ and \f$1 \equiv -a_0d \pmod b\f$.
 * This engine uses the same output function as AWC/SWB generators
 * \f$
 *   u_n = \sum_{j=1}^L x_{Ln + j + 1} b^{-j}
 * \f$ and the results of \cite rTEZ93a can be tweaked as in \cite rCOU97a.
 * Take \f$M = \sum_{l = 0}^k a_k b^l\f$ and \f$0 < A < m\f$ with
 * \f$1 \equiv Ab \pmod m\f$, then the same recurrence
 * \f{align}{
 *   X_n & = AX_{n-1} \pmod M \\
 *   v_n & = X_n / M \\
 *   w_n & = X_{Ln}/M.
 * \f}
 * is equivalent to the MWC generator with the same precision:
 * \f$u_i = b^{-L} \lfloor b^L w_i \rfloor\f$.
 *
 * \subsection back_gen_comb Combined Generators
 *
 * Generators using a carry can easily be constructed to have a large period and
 * to operate very fast, but the fact that they are equivalent to LCGs means
 * that their structure is most of the time flawed, especially in 2 dimensions.
 * To solve this problem, it was suggested to use multiple MRGs and to combine
 * their output. This reduces the computing cost of big MRGs, while obtaining
 * much better distribution than carry generators.
 *
 * Let sequences \f$\{\{x_n^{(1)}\},\{x_n^{(2)}\},\ldots,\{x_n^{(\ell)}\}\}\f$
 * and \f$\{\{u_n^{(1)}\},\{u_n^{(2)}\},\ldots,\{u_n^{(\ell)}\}\}\f$ be produced by
 * MRGs with \f$a_{i,j}\f$ the j-th coefficient of the i-th recurrence,
 * \f$k_i\f$ the order of the i-th recurrence and \f$m_i\f$ the modulus of the
 * i-th recurrence. It is possible to get
 * pseudo-random numbers as:
 * \f[
 *   \begin{array}{lll}
 *     \tilde{u}_n & = & \left(\sum_{i = 1}^\ell \delta_{i} x_n^{(i)} \pmod {m_1} \right) / m_1 \\
 *     w_n & = & \sum_{i = 1}^\ell \frac{\delta_{i} x^{(i)}_n}{m_i} \pmod 1.
 *   \end{array}
 * \f]
 *
 * \cite rLEC96b presents a way to build a MRG that has an output \f$\{u_n\}\f$
 * identical to \f$\{w_n\}\f$ if their first \f$k = \max(k_1, \ldots, k_\ell)\f$
 * output values are the same. Define
 * \f{align}{
 *   m & = \prod_{i = 1}^\ell m_i \\
 *   b & = \sum_{i=1}^\ell \frac{\delta_i b_i m}{m_i} \pmod m \\
 *   n_j & \text{with } 1 \equiv n_j (m /m_j) \pmod {m_j},\ 1 \leq j \leq \ell \\
 *   a_j & = \sum_{i=1}^\ell \frac{a_{i,j} n_i m}{m_i} \pmod m,\ 1 \leq j \leq k.
 * \f}
 * Then if \f$(u_0, \ldots, u_{k-1}) = (w_0, \ldots, w_{k-1})\f$, then \f$w_n = u_n\f$
 * for all \f$n\in\mathbb{N}\f$ given
 * \f{align}{
 *   x_n & = a_1 x_{n-1} + \cdots + a_k x_{n-k} + b \pmod m \\
 *   u_n & = x_n/m.
 * \f}
 *
 * \subsection back_gen_mat Matrix Generators
 *
 * The final type of generator that we present is slightly different. This is
 * because it cannot be transformed to an equivalent MRG. Instead, this is a
 * generalization of an MRG.
 *
 * Take \f$\mathbf{A}\in \mathbb{Z}^{k\times k}\f$ and \f$s_n \in \mathbb{Z}^k\f$.
 * We can generate a random number vector with
 * \f[
 *   s_n = \mathbf{A} s_{n-1} \pmod m
 * \f]
 * and \f$\mathbf{u}_n = (1/m) \cdot s_n\f$. This is what we call a **matrix
 * multiple recursive generator** (MMRG). This kind of generator can also be
 * used to generate any size of vector, including single random numbers. Let
 * \f$\mathbf{u}_n(i)\f$ be the i-th component for vector \f$\mathbf{u}_n\f$ and
 * \f$p = qk + r,\ 0 \leq r < k\f$ be the size of vectors wanted. We can get the
 * random vector sequence
 * \f$\{v_n = (\mathbf{u}_{n(q+1)}(1), \ldots, \mathbf{u}_{n(q+1)}(k), \ldots,
 * \mathbf{u}_{n(q+1)+q}(1), \ldots, \mathbf{u}_{n(q+1)+q}(r)) \in \mathbb{Z}^p\}\f$.
 *
 * We will see below that a MRG of order \f$k\f$
 * with multipliers \f$(a_1, \ldots, a_k)\f$ and modulo \f$m\f$ has the same
 * output structure as a MMRG with
 * \f[
 *   \mathbf{A} = \begin{bmatrix}
 *         0 & 1 & 0 & \cdots & 0 \\
 *         0 & 0 & 1 & \ddots & 0 \\
 *         \vdots &  & \ddots & \ddots & \vdots \\
 *         0 & \cdots &Â \cdots & 0 & 1 \\
 *         a_1 & a_2 & \cdots & \cdots & a_k
 *       \end{bmatrix}^k
 * \f]
 *
 * \section back_other Lattices and Merit
 *
 * As explained in \ref lattice_back, lattices of dimension \f$t\f$ are discrete
 * subgroups of \f$\mathbb{R}^t\f$ generated by the integer combinations of a
 * set of linearly independant (over the integers) vectors. We now explain how
 * random number generators of the MRG familly can be studied from the lattice
 * of their points, and how to obtain the lattice of these generators.
 *
 * \subsection back_lat Lattice of a MRG
 *
 * Take \f[\Psi_t = \{ \mathbf{u}_0 =(x_0 /m, \ldots, x_{t-1}/m): (x_0, \dots, x_{k-1}) \in \mathbb{Z}_m^k\}\f]
 * for a MRG of order \f$k\f$. This is the set of all first \f$t\f$ components vectors
 * the generator will output. The periodic contination of this set is a lattice.
 * We will name this lattice \f$L_t\f$, thus
 * \f[
 *   \Psi_t + \mathbb{Z}^t = L_t.
 * \f]
 * This lattice has basis
 * \f[
 *   \mathbf{V} = \begin{pmatrix}
 *     1/m & 0 & \dots & 0 & x_{1,k+1} & \dots & x_{1,t} \\
 *     0 & 1/m & \dots & 0 & x_{2,k+1} & \dots & x_{2,t} \\
 *     \vdots & \vdots & \ddots & \vdots & \vdots & & \vdots \\
 *     0 & 0 & \dots & 1/m & x_{k,k+1} & \dots & x_{k,t} \\
 *     0 & 0 & \dots & 0 & 1 & \dots & 0 \\
 *     \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
 *     0 & 0 & \dots & 0 & 0 & \dots & 1 \end{pmatrix}
 * \f]
 * and its dual has basis
 * \f[
 *   \mathbf{W} = \begin{pmatrix}
 *     m & 0 & \dots & 0 & 0 & \dots & 0 \\
 *     0 & m & \dots & 0 & 0 & \dots & 0 \\
 *     \vdots & \vdots & \ddots & \vdots & \vdots & & \vdots \\
 *     0 & 0 & \dots & m & 0 & \dots & 0 \\
 *     -x_{1,k+1} & -x_{2,k+1} & \dots & -x_{k,k+1} & 1 & \dots & 0 \\
 *     \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
 *     -x_{1,t} & -x_{2,t} & \dots & -x_{k,t} & 0 & \dots & 1 \end{pmatrix}.
 *   \f]
 * Where \f$x_{i,j}\f$ is the \f$j\f$-th x value of the generator with initial
 * state \f$ \mathbf{e}_i = (0, \dots, 1, \dots, 0) \in \mathbb{Z}^k\f$, the \f$i\f$-th
 * canonical vector in dimension \f$k\f$. LatMRG can build this lattice for any
 * of the generators mentioned.
 *
 * ## Lacunary indices
 *
 *   Instead of forming vectors with successive values like in the above
 * definition of \f$\Psi_t\f$, one can form vectors with values that are
 * some distance apart in the sequence (so-called "leapfrog" values).
 * a set of fixed integers. Define
 * \f[
 *   \Psi_t(I) = \{(u_{i_1},â¦,u_{i_t}) \mid(x_0,â¦,x_{k-1}) \in\mathbb{Z}_m^k\}
 * \f]
 * and let \f$L_t(I) = \Psi_t(I) + \mathbb{Z}^t\f$. If we assume that
 * \f$0\le i_1 < i_2 < \cdots< i_t\f$, this \f$L_t(I)\f$ is the projection
 * of the lattice \f$L_{i_t+1}\f$ over the \f$t\f$-dimensional subspace
 * determined by the coordinates that belong to \f$I\f$.
 * For
 * \f$(i_1,â¦,i_t) = (0,â¦,t-1)\f$, one has \f$L_t(I) = L_t\f$.
 * Using what is available
 * in *LatticeTester* one can build a basis for \f$L_t\f$ and its dual in
 * this more general case. This means LatMRG can perform the usual lattice
 * analysis on these kind of lattice also.
 * Further details and examples are given in \cite rLEC97c.
 *
 * \subsection back_merit Measures on MRGs
 *
 * The lattice structure also means that all points of \f$L_t\f$ lie in a
 * family of equidistant parallel hyperplanes. Examining geometrical properties
 * of these hyperplanes provides information on the uniformity of
 * of the random numbers generated. Another important property that can be
 * used to study of MRGs is their period length. Although a long
 * period does not garantee good uniformity, it is ideal for better distribution
 * properties.
 *
 * \subsubsection back_merit_per Period Length
 *
 * \subsubsection back_merit_spectral Figures of Merit
 *
 * Among all such families
 * hyperplanes that cover all the points, choose the one for which the
 * successive hyperplanes are farthest apart. The distance between these
 * successive hyperplanes is equal to \f$1/\ell_t\f$ where
 * \f$\ell_t\f$ is the Euclidean length of the shortest nonzero vector in
 * the *dual* lattice \f$L_t^*\f$. It is possible to normalize this value, such
 * as to obtain the *spectral test* for the lattice.
 *
 * To build figures of merit from the spectral test, we take the worst-case value of
 * \f$\ell_t/\ell_t^*(m^k)\f$ over certain values of \f$t\f$ and for
 * selected projections on lower-dimensional subspaces. More specifically,
 * let \f$\ell_I\f$ denote the length of the shortest nonzero vector
 * \f$\mathbf{v}\f$ in \f$L_t^*(I)\f$, and \f$\ell_t =
 * \ell_{\{1,â¦,t\}}\f$ as before. For arbitrary positive integers
 * \f$t_1\ge\cdots\ge t_d \ge d\f$, consider the worst-case figure of merit
 * \f[
 *   M_{t_1,â¦,t_d} = \min\left[ \min_{k+1\le t\le t_1} \ell_t/\ell_t^*(m^k),\min_{2\le s\le k} \min_{I\in S(s,t_s)} \ell_I/m, \min_{k+1\le s\le d} \min_{I\in S(s,t_s)} \ell_I/\ell_s^*(m^k) \right],
 * \f]
 * where \f$S(s,t_s) = \{I=\{i_1,â¦,i_s\} \mid1 = i_1 <
 * \cdots< i_s\le t_s\}\f$. This figure of merit makes sure that the lattice
 * is good in projections over \f$t\f$ successive dimensions for all
 * \f$t\le t_1\f$, and over non-successive dimensions that are not too far
 * apart. Note that when \f$s\le k\f$, the smallest distance between
 * hyperplanes that can be achieved in \f$s\f$ dimensions for the MRG is
 * \f$1/m\f$ because it is possible for the generator to span all points with
 * coordinates \f$z/m\f$ with \f$z\in \mathbb{Z}\f$.
 *
 * The figure of merit \f$M_{t_1} =
 * \min_{2\le s\le t_1} \ell_s/\ell_s^*(n)\f$ (with \f$d=1\f$) has been
 * widely used for ranking and selecting LCGs and MRGs \cite sFIS96a,
 * \cite rLEC99b, \cite rLEC99c. The quantity \f$M_{t_1,â¦,t_d}\f$ is
 * a worst case over \f$(t_1-d) +
 * \sum_{s=2}^d \binom{t_s-1}{s-1}\f$ projections, and this number increases
 * quickly with \f$d\f$ unless the \f$t_s\f$ are very small.
 *
 * When too many projections are considered, there are
 * inevitably some that are bad. The worst-case figure of merit is
 * (practically) always small, and cannot distinguish between good and
 * mediocre behavior in the most important projections. Moreover, the time to
 * compute \f$M_{t_1,â¦,t_d}\f$ increases with the number of projections. We
 * therefore suggest considering only the projections deemed important when
 * first comparing generators. It is then possible to compare good generators
 * for those projections more extensively. We suggest using the criterion  with \f$d\f$ equal
 * to 4 or 5, and \f$t_s\f$ decreasing with \f$s\f$.
 *
 * Instead of considering the shortest nonzero vector in the dual lattice,
 * one can consider the shortest nonzero vector in the primal lattice
 * \f$L_t\f$. Its length represents the distance to the nearest other lattice
 * point from any point of the lattice. A small value means that many points
 * are placed on the same line, at some fixed distance apart.
 *
 * \subsection minkowski Minkowski reduced basis
 *
 * Another way of measuring the quality of a lattice is in terms of the
 * relative lengths of the smallest and largest vectors in a *reduced* basis.
 * It has been historicaly important to use this ratio for a Minkowski-reduced basis (MRLB)
 * (see \cite rAFF85a, \cite rAFF88a, \cite rGRO88a for more
 * details). Roughly, a MRLB is a basis for which the vectors are in some
 * sense the most orthogonal.
 *
 * The ratio of the sizes of the shortest and
 * longest vectors of a MRLB is called its *Beyer-quotient*. In general, a
 * given lattice may have several MRLBs, all with the same length of the
 * shortest vector, but perhaps with different lengths of the longest vector,
 * and thus different Beyer quotients. We define \f$q_t(I)\f$ as the maximum
 * of the Beyer quotients of all MRLBs of \f$L_t(I)\f$, and denote
 * \f$q_t(\{1,â¦,t\})\f$ by \f$q_t\f$. We prefer values of \f$q_t(I)\f$ close
 * to 1. Similar to \f$M_{t_1,â¦,t_d}\f$, we define
 *   \f[
 *     Q_{t_1,â¦,t_d} = \min\left[ \min_{k+1\le t\le t_1} q_t,\min_{2\le s\le d} \min_{I\in S(s,t_s)} q_t(I) \right]. \tag{Q}
 *   \f]
 *
 * Since computing \f$q_t\f$ is much more time consuming than computing the
 * spectral test and this mesure is not unique, this test is seldom used nowadays.
 *
 * \section back_param A Good Parameter Choice
 *
 * The choice of modulo is a recurrent source of discussion when building such
 * generators. This is because a modulo operation takes a variable time for
 * variable modulus. Most of the time, there is a compromise to do between
 * simple modulus like \f$2^q\f$ (which can be computed with a
 * simple xor operation) and \f$p\f$ big prime number. The former is much faster
 * to compute, but the latter usually performs much better in theoretical and
 * statistical tests.
 *
 * \section numbers_sec Large numbers, matrices and polynomials
 *
 * LatMRG can deal with very large moduli and multipliers. There is no
 * limit on size other than the size of the computer memory (and the CPU
 * time). For example, a generator with a modulus of a few hundred bits can
 * be analyzed easily. Operations on large integers are performed using the
 * GNU multi-precision package GMP \cite iGMP06a. GMP is a portable
 * library written in C for arbitrary precision arithmetic on integers,
 * rational numbers, and floating-point numbers. For vectors, matrices of
 * large numbers and polynomials, we use NTL \cite iSHO05a. NTL is a
 * high-performance, portable C++ library providing data structures and
 * algorithms for manipulating arbitrary length integers, and for vectors,
 * matrices, and polynomials over the integers and over finite fields. NTL
 * uses GMP as an underlying package for dealing with large numbers.
 *
 * Of course, arithmetic operations with these structures are performed in
 * software and are significantly slower than the standard operations
 * supported by hardware. For this reason, most of the basic (low-level)
 * operations required by our higher-level classes have been implemented in
 * two or three versions. When building a basis or checking maximal period
 * conditions, the modulus and multipliers can be represented either as
 * <tt>int64_t</tt>âs (64-bit integers) or <tt>ZZ</tt>âs (arbitrary large
 * integers). After a lattice basis and its dual have been constructed, when
 * working on the basis (finding a shortest vector, Minkowski reduction,
 * etc.), the vector elements can be represented either as <tt>double</tt>âs
 * (64-bit floating-point numbers) or <tt>RR</tt>âs (arbitrary large
 * floating-point numbers).
 *
 * When performing a search for good generators, for instance, one can
 * first perform all the "screening" computations (involving many generators)
 * using standard type <tt>int64_t</tt>, and then recompute (verify) with the
 * large floating-point numbers <tt>RR</tt> only for the retained generators.
 *
 * **Beware!** A lot of the manipulations needed for 64 bits generators need
 * more that 64 bits. Using `int64_t` to search and test 64 bits generators
 * might cause overflows.
 * */

 *   We can view the lattice as a way of packing the space by spheres of
 * radius \f$\ell_t/2\f$, with one sphere centered at each lattice point. In
 * the dual lattice, this gives \f$1/n = m^{-k}\f$ spheres per unit volume.
 * If we rescale so that the radius of each sphere is 1, we obtain
 * \f$\delta_t = (\ell_t/2)^t/n\f$ spheres per unit volume. This number
 * \f$\delta_t\f$ is called the *center density* of the lattice. For a given
 * value of \f$n\f$, an upper bound on \f$\ell_t\f$ can be obtained in terms
 * of an upper bound on \f$\delta_t\f$ [one has \f$\ell_t = 2
 * (n\delta_t)^{1/t}\f$], and vice-versa. Let \f$\delta_t^*\f$ be the
 * largest possible value of \f$\delta_t\f$ for a lattice (i.e., the densest
 * packing by non-overlapping spheres arranged in a lattice). The quantity
 * \f$\gamma_t = 2(\delta_t^*)^{2/t}\f$ is called the *Hermite constant*
 * for dimension \f$t\f$ \cite mCON99a, \cite mGRU87a. It gives the
 * upper bound \f$\ell_t^2\le(\ell_t^*(n))^2 = 2(n\delta_t^*)^{2/t} =
 * \gamma_t n^{2/t}\f$ for a lattice of density \f$1/n\f$. Knowing the
 * Hermite constants, or good approximations of them, is useful because it
 * allows us to normalize \f$\ell_t\f$ to a value between 0 and 1 by taking
 * \f$\ell_t/\ell_t^*(m^k)\f$. This is convenient for comparing values for
 * different values of \f$t\f$ and \f$m^k\f$. Good values are close to 1 and
 * bad values are close to 0.
 *
 *   The Hermite constants are known exactly only for \f$t\le8\f$, in which
 * case the densest lattice packings are attained by the *laminated* lattices
 * \cite mCON99a. Conway and Sloane \cite mCON99a (Table 1.2)
 * give the values of \f$\delta_t^*\f$ for \f$t\le8\f$, and provide lower
 * and upper bounds on \f$\delta_t^*\f$ for other values of \f$t\f$. The
 * largest value of \f$\ell_t^2/n^{2/t}\f$ obtained so far for concrete
 * lattice constructions is a lower bound on \f$\gamma_t\f$, which we denote
 * by \f$\gamma_t^{\mathrm{B}}\f$. Such values are given in Table 1.2 of
 * \cite mCON99a, page 15, in terms of \f$\delta^*\f$. The laminated
 * lattices, which give the lower bound
 * \f$\ell_t^2/n^{2/t} \ge\gamma_t^{\mathrm{L}} = 4
 * \lambda_t^{-1/t}\f$, where the constants \f$\lambda_t\f$ are given in
 * \cite mCON88a (Table 6.1, page 158) for \f$t\le48\f$, are the
 * best constructions in dimensions 1 to 29, except for dimensions 10 to 13.
 * (One has \f$\gamma_t^{\mathrm{L}} = \gamma_t\f$ for \f$t\le8\f$.)
 *
 *   Minkowski proved that there exists lattices with density satisfying
 * \f$\delta_t \ge\zeta(t) / (2^{t-1} V_t)\f$ where \f$\zeta(t) =
 * \sum_{k=1}^{\infty}k^{-t}\f$ is the Riemann zeta function and \f$V_t =
 * \pi^{t/2} / (t/2)!\f$ is the volume of a \f$t\f$-dimensional sphere of
 * radius 1. This bound provides a lower bound \f$\gamma_t^Z\f$ on
 * \f$\gamma_t\f$.
 *
 *   An upper bound on \f$\gamma_t\f$ is obtained via the bound of Rogers on
 * the density of sphere packings \cite mCON99a. This upper bound can
 * be written as
 * \f[
 *   \gamma_t^{\mathrm{R}} = 4* 2^{2R(t)/t}
 *   \f]
 * where \f$R(t)\f$ can be found in Table&nbsp;1.2 of \cite mCON99a
 * for \f$t\le24\f$, and can be approximated with \f$O(1/t)\f$ error and
 * approximately 4 decimal digits of precision, for \f$t\ge25\f$, by
 * \f[
 *     R(t) = \frac{t}{2} \log_2\left(\frac{t}{4\pi e}\right) + \frac{3}{2} \log_2 (t) - \log_2 \left(\frac{e}{\sqrt{\pi}}\right) + \frac{5.25}{t + 2.5}.
 *   \f]
 * Table&nbsp;1 in \cite rLEC99c gives the ratio
 * \f$(\gamma_t^{\mathrm{L}} / \gamma_t^{\mathrm{R}})^{1/2}\f$, of the
 * lower bound over the upper bound on \f$\ell_t\f$, for
 * \f$1\le t\le48\f$. This ratio tends to decrease with \f$t\f$, but not
 * monotonously.
 *
 *   Computing the shortest vector in terms of the Euclidean norm is
 * convenient, e.g., for computational reasons, but one can also use another
 * norm instead. For example, one can take the
 * \f$\mathcal{L}_p\f$-norm, defined by \f$\Vert\mathbf{v}\Vert_p =
 * (|v_1|^p + \cdots+ |v_t|^p)^{1/p}\f$ for \f$1\le p < \infty\f$ and
 * \f$\Vert\mathbf{v}\Vert_{\infty}= \max(|v_1|, â¦, |v_t|)\f$ for \f$p =
 * \infty\f$. The inverse of the length of the shortest vector is then the
 * \f$\mathcal{L}_p\f$-distance between the successive hyperplanes for the
 * family of hyperplanes that are farthest apart among those that cover
 * \f$L_t\f$. For \f$p=1\f$, the length \f$\ell_t =
 * \Vert\mathbf{v}\Vert_1\f$ of the shortest vector \f$\mathbf{v}\f$ (or
 * \f$\Vert\mathbf{h}\Vert_1 - 1\f$ in some cases, see
 * \cite rKNU97a) is the minimal number of hyperplanes that cover all
 * the points of \f$\Psi_t\f$. The following upper bound on \f$\ell_t\f$ in
 * this case was established by Marsaglia \cite rMAR68a by applying
 * the general convex body theorem of Minkowski:
 * \f[
 *   \ell_t \le\ell_t^*(m^k) = (t! m^k)^{1/t} =: \gamma_t^M m^{k/t}.
 *   \f]
 * This upper bound can be used to normalize \f$\ell_t\f$ in this case.
 *
 *   â Upper bound on \f$\ell_t\f$ in general: Minkowski. ?

